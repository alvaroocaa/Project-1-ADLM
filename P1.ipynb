{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d598db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub pathlib pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299352fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import kagglehub\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ee7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"harbhajansingh21/german-traffic-sign-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "data_dir = pathlib.Path(path)\n",
    "\n",
    "train_dir = data_dir / \"train.p\"\n",
    "test_dir  = data_dir / \"test.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8db4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14caf207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data(os.path.join(path, \"train.p\"))\n",
    "valid_images, valid_labels = load_data(os.path.join(path, \"valid.p\"))\n",
    "test_images, test_labels   = load_data(os.path.join(path, \"test.p\"))\n",
    "\n",
    "sign_df = pd.read_csv(os.path.join(path, \"signname.csv\"))\n",
    "class_names = sign_df[\"SignName\"].tolist()\n",
    "\n",
    "print(train_images.shape)  # e.g. (34799, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "NUM_CLASSES = 43  # Used in transform\n",
    "CLASSES = 43      # Used in model build\n",
    "INPUT_SIZE = 64 \n",
    "CANVAS = 64       # Used in transform\n",
    "OBJ_SIZE = 48     # Used in transform\n",
    "BATCH_SIZE = 64   # Used in data loader\n",
    "INPUT_SHAPE = (64, 64, 3)\n",
    "\n",
    "# %% [NEW TRANSFORM] - Adds Rotation and Zoom\n",
    "def transform(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # 1. Aggressive Color Augmentation\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "\n",
    "    # 2. Geometric Augmentation (Crucial for Generalization)\n",
    "    # We resize slightly larger then crop to simulate zoom/translation\n",
    "    image = tf.image.resize(image, (OBJ_SIZE + 8, OBJ_SIZE + 8))\n",
    "    image = tf.image.random_crop(image, size=[OBJ_SIZE, OBJ_SIZE, 3])\n",
    "\n",
    "    # 3. Canvas Placement (Your existing logic)\n",
    "    xmin = tf.random.uniform((), 0, CANVAS - OBJ_SIZE, dtype=tf.int32)\n",
    "    ymin = tf.random.uniform((), 0, CANVAS - OBJ_SIZE, dtype=tf.int32)\n",
    "    image = tf.image.pad_to_bounding_box(image, ymin, xmin, CANVAS, CANVAS)\n",
    "\n",
    "    # BBox math\n",
    "    xmin_f = tf.cast(xmin, tf.float32) / CANVAS\n",
    "    ymin_f = tf.cast(ymin, tf.float32) / CANVAS\n",
    "    xmax_f = tf.cast(xmin + OBJ_SIZE, tf.float32) / CANVAS\n",
    "    ymax_f = tf.cast(ymin + OBJ_SIZE, tf.float32) / CANVAS\n",
    "    bbox = tf.stack([xmin_f, ymin_f, xmax_f, ymax_f])\n",
    "\n",
    "    return image, (tf.one_hot(label, NUM_CLASSES), bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.shuffle(5000)\n",
    "train_ds = train_ds.map(transform, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_val(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # fixed placement (center)\n",
    "    xmin = (CANVAS - OBJ_SIZE) // 2\n",
    "    ymin = (CANVAS - OBJ_SIZE) // 2\n",
    "\n",
    "    image = tf.image.pad_to_bounding_box(image, ymin, xmin, CANVAS, CANVAS)\n",
    "\n",
    "    xmin_f = xmin / CANVAS\n",
    "    ymin_f = ymin / CANVAS\n",
    "    xmax_f = (xmin + OBJ_SIZE) / CANVAS\n",
    "    ymax_f = (ymin + OBJ_SIZE) / CANVAS\n",
    "\n",
    "    bbox = tf.stack([xmin_f, ymin_f, xmax_f, ymax_f])\n",
    "\n",
    "    return image, (tf.one_hot(label, NUM_CLASSES), bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d13d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_images, valid_labels))\n",
    "valid_ds = valid_ds.map(transform_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(256)\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840eb7e4",
   "metadata": {},
   "source": [
    "# Visualization Utilities\n",
    "\n",
    "These functions are used to draw bounding boxes around the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9befdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 64\n",
    "im_height = 64\n",
    "use_normalized_coordinates = True\n",
    "iou_threshold = 0.5\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image_array(image,\n",
    "                                       boxes,\n",
    "                                       color=('red',),\n",
    "                                       thickness=2,\n",
    "                                       display_str_list=()):\n",
    "    \"\"\"\n",
    "    image: numpy array (64,64,3)\n",
    "    boxes: [N,4] in format [xmin, ymin, xmax, ymax] normalized\n",
    "    \"\"\"\n",
    "\n",
    "    image_pil = PIL.Image.fromarray(image.astype(np.uint8)).convert(\"RGB\")\n",
    "    draw = PIL.ImageDraw.Draw(image_pil)\n",
    "\n",
    "    im_width, im_height = image_pil.size\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "\n",
    "        left   = xmin * im_width\n",
    "        right  = xmax * im_width\n",
    "        top    = ymin * im_height\n",
    "        bottom = ymax * im_height\n",
    "\n",
    "        draw.rectangle(\n",
    "            [(left, top), (right, bottom)],\n",
    "            outline=color[i % len(color)],\n",
    "            width=thickness\n",
    "        )\n",
    "\n",
    "        if display_str_list:\n",
    "            draw.text((left, top - 10),\n",
    "                      display_str_list[i],\n",
    "                      fill=color[i % len(color)])\n",
    "\n",
    "    return np.array(image_pil)\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image(image,\n",
    "                                 boxes,\n",
    "                                 color = [],\n",
    "                                 thickness = 1,\n",
    "                                 display_str_list = ()):\n",
    "  \"\"\"Draws bounding boxes on image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: a list of strings for each bounding box.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  boxes_shape = boxes.shape\n",
    "  if not boxes_shape:\n",
    "    return\n",
    "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "    raise ValueError('Input must be of size [N, 4]')\n",
    "  for i in range(boxes_shape[0]):\n",
    "    draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3],\n",
    "                               boxes[i, 2], color[i], thickness, display_str_list[i])\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color = 'red',\n",
    "                               thickness = 1,\n",
    "                               display_str = None,\n",
    "                               use_normalized_coordinates = True):\n",
    "  \"\"\"Adds a bounding box to an image.\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: string to display in box\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  draw = PIL.ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width = thickness, fill = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9583a62",
   "metadata": {},
   "source": [
    "These utilities are used to visualize the data and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains helper functions used for visualization\n",
    "and downloads only.\n",
    "\n",
    "You can skip reading it, as there is very\n",
    "little Keras or Tensorflow related code here.\n",
    "\"\"\"\n",
    "\n",
    "# Matplotlib config\n",
    "plt.rc('image', cmap='gray')\n",
    "plt.rc('grid', linewidth=0)\n",
    "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
    "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
    "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
    "plt.rc('text', color='a8151a')\n",
    "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
    "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
    "\n",
    "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
    "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
    "\n",
    "    batch_train_ds = training_dataset.unbatch().batch(N)\n",
    "\n",
    "    for val_imgs, (val_labels, val_boxes) in validation_dataset.take(1):\n",
    "        validation_images = val_imgs.numpy()\n",
    "        validation_labels = np.argmax(val_labels.numpy(), axis=1)\n",
    "        validation_boxes  = val_boxes.numpy()\n",
    "\n",
    "    for train_imgs, (train_labels, train_boxes) in batch_train_ds.take(1):\n",
    "        training_images = train_imgs.numpy()\n",
    "        training_labels = np.argmax(train_labels.numpy(), axis=1)\n",
    "        training_boxes  = train_boxes.numpy()\n",
    "\n",
    "    return (training_images, training_labels, training_boxes,\n",
    "            validation_images, validation_labels, validation_boxes)\n",
    "\n",
    "\n",
    "# create digits from local fonts for testing\n",
    "def create_digits_from_local_fonts(n):\n",
    "  font_labels = []\n",
    "  img = PIL.Image.new('LA', (64*n, 64), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
    "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
    "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
    "  d = PIL.ImageDraw.Draw(img)\n",
    "  for i in range(n):\n",
    "    font_labels.append(i%10)\n",
    "    d.text((7+i*64,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
    "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
    "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [64, 64*n]), n, axis=1), axis=0), [n, 64*64])\n",
    "  return font_digits, font_labels\n",
    "\n",
    "\n",
    "# utility to display a row of digits with their predictions\n",
    "def display_digits_with_boxes(images,\n",
    "                              predictions,\n",
    "                              labels,\n",
    "                              pred_bboxes,\n",
    "                              true_bboxes,\n",
    "                              iou,\n",
    "                              title):\n",
    "\n",
    "    n = 10\n",
    "    indexes = np.random.choice(len(images), size=n)\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for i, idx in enumerate(indexes):\n",
    "\n",
    "        ax = plt.subplot(1, n, i+1)\n",
    "\n",
    "        # convert to uint8 for drawing\n",
    "        img = images[idx].astype(np.uint8)\n",
    "\n",
    "        boxes = []\n",
    "        colors = []\n",
    "        names = []\n",
    "\n",
    "        if len(true_bboxes):\n",
    "            boxes.append(true_bboxes[idx])\n",
    "            colors.append('green')\n",
    "            names.append(\"true\")\n",
    "\n",
    "        if len(pred_bboxes):\n",
    "            boxes.append(pred_bboxes[idx])\n",
    "            colors.append('red')\n",
    "            names.append(\"pred\")\n",
    "\n",
    "        if boxes:\n",
    "            img = draw_bounding_boxes_on_image_array(\n",
    "                img,\n",
    "                np.array(boxes),\n",
    "                color=colors,\n",
    "                display_str_list=names\n",
    "            )\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        pred_class = predictions[idx]\n",
    "        true_class = labels[idx]\n",
    "\n",
    "        title_color = \"red\" if pred_class != true_class else \"black\"\n",
    "        ax.set_title(class_names[pred_class], color=title_color, fontsize=9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title, ylim=None, smooth=False):\n",
    "    plt.figure(figsize=(6,4))\n",
    "\n",
    "    train = history.history[metric_name]\n",
    "    val   = history.history.get('val_' + metric_name)\n",
    "\n",
    "    # optional smoothing (helps noisy validation curves)\n",
    "    if smooth:\n",
    "        import numpy as np\n",
    "        def smooth_curve(data, weight=0.6):\n",
    "            smoothed = []\n",
    "            last = data[0]\n",
    "            for point in data:\n",
    "                last = last * weight + (1 - weight) * point\n",
    "                smoothed.append(last)\n",
    "            return smoothed\n",
    "        train = smooth_curve(train)\n",
    "        if val:\n",
    "            val = smooth_curve(val)\n",
    "\n",
    "    plt.plot(train, label=\"Train\", linewidth=2)\n",
    "\n",
    "    if val:\n",
    "        plt.plot(val, label=\"Validation\", linewidth=2)\n",
    "\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric_name)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(0, ylim)\n",
    "\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7de74",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_digits, training_labels, training_bboxes,\n",
    " validation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(train_ds, valid_ds, 10)\n",
    "\n",
    "display_digits_with_boxes(\n",
    "    training_digits,\n",
    "    training_labels,\n",
    "    training_labels,\n",
    "    np.array([]),\n",
    "    training_bboxes,\n",
    "    np.array([]),\n",
    "    \"training images and their labels\"\n",
    ")\n",
    "\n",
    "display_digits_with_boxes(\n",
    "    validation_digits,\n",
    "    validation_labels,\n",
    "    validation_labels,\n",
    "    np.array([]),\n",
    "    validation_bboxes,\n",
    "    np.array([]),\n",
    "    \"validation images and their labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. Update Constants (keep these)\n",
    "CLASSES = 43\n",
    "INPUT_SIZE = 64\n",
    "INPUT_SHAPE = (INPUT_SIZE, INPUT_SIZE, 3)\n",
    "\n",
    "def build_transfer_learning_model():\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    # Start frozen\n",
    "    base_model.trainable = False \n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "    \n",
    "    features = base_model(x, training=False)\n",
    "    \n",
    "    # Use Global Max Pooling alongside Average Pooling for better feature capture\n",
    "    gap = tf.keras.layers.GlobalAveragePooling2D()(features)\n",
    "    gmp = tf.keras.layers.GlobalMaxPooling2D()(features)\n",
    "    shared = tf.keras.layers.Concatenate()([gap, gmp])\n",
    "    \n",
    "    # Classification Head - Reduced to 512 + Higher Dropout\n",
    "    class_branch = tf.keras.layers.Dense(512, activation='relu')(shared)\n",
    "    class_branch = tf.keras.layers.BatchNormalization()(class_branch)\n",
    "    class_branch = tf.keras.layers.Dropout(0.5)(class_branch) # Increased from 0.3\n",
    "    class_branch = tf.keras.layers.Dense(256, activation='relu')(class_branch)\n",
    "    class_branch = tf.keras.layers.Dropout(0.3)(class_branch)\n",
    "    class_out = tf.keras.layers.Dense(CLASSES, activation='softmax', name='classifier_head')(class_branch)\n",
    "    \n",
    "    # Regression Head\n",
    "    reg_branch = tf.keras.layers.Dense(128, activation='relu')(shared)\n",
    "    reg_branch = tf.keras.layers.Dropout(0.2)(reg_branch)\n",
    "    bbox_out = tf.keras.layers.Dense(4, activation='sigmoid', name='regressor_head')(reg_branch)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[class_out, bbox_out])\n",
    "\n",
    "# 3. BUILD AND COMPILE\n",
    "model = build_transfer_learning_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Use a lower learning rate to prevent the loss spikes you saw\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), # Faster start\n",
    "    loss={\"classifier_head\": \"categorical_crossentropy\", \"regressor_head\": \"mse\"},\n",
    "    loss_weights={\"classifier_head\": 10.0, \"regressor_head\": 1.0},\n",
    "    metrics={\"classifier_head\": \"accuracy\", \"regressor_head\": \"mse\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place this before your first training cell\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_classifier_head_loss', # We monitor the head you want to improve\n",
    "    factor=0.2,                         # Drop LR by 5x when it plateaus\n",
    "    patience=3,                         # Wait 3 epochs before droppi\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# In your existing frozen training cell:\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[lr_scheduler] # Add it here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dynamically find the base_model\n",
    "base_model_layer = next(l for l in model.layers if 'mobilenetv2' in l.name)\n",
    "base_model_layer.trainable = True\n",
    "\n",
    "# 2. Unfreeze from 110 instead of 80 to reduce overfitting\n",
    "for layer in base_model_layer.layers[:110]: \n",
    "    layer.trainable = False\n",
    "    \n",
    "# 3. POINT 3: Re-compile with extreme classification focus (Weight 40.0)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Very slow for fine-tuning\n",
    "    loss={\"classifier_head\": \"categorical_crossentropy\", \"regressor_head\": \"mse\"},\n",
    "    loss_weights={\"classifier_head\": 0.9, \"regressor_head\": 0.1}, # Focus on classes\n",
    "    metrics={\"classifier_head\": \"accuracy\", \"regressor_head\": \"mse\"}\n",
    ")\n",
    "\n",
    "# 4. Use the updated patience for the scheduler\n",
    "lr_scheduler.patience = 5\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_classifier_head_accuracy', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Train\n",
    "history_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"regressor_head_mse\", \"Bounding Box MSE\", ylim=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d291ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"classifier_head_accuracy\",\n",
    "             \"Classification Accuracy\",\n",
    "             ylim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c590bab",
   "metadata": {},
   "source": [
    "## Intersection over union\n",
    "\n",
    "Calculate the I-O-U metric to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18164c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(pred_box, true_box):\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred =  np.split(pred_box, 4, axis = 1)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n",
    "\n",
    "    smoothing_factor = 1e-10\n",
    "\n",
    "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
    "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
    "    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n",
    "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
    "\n",
    "    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
    "    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
    "\n",
    "    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n",
    "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
    "\n",
    "    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89878833",
   "metadata": {},
   "source": [
    "### Visualize predictions\n",
    "The following code will make predictions and visualize both the classification and the predicted bounding boxes.\n",
    "- The true bounding box labels will be in green, and the model's predicted bounding boxes are in red.\n",
    "- The predicted number is shown below the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize validation digits\n",
    "predictions = model.predict(validation_digits, batch_size=64)\n",
    "predicted_labels = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "predicted_bboxes = predictions[1]\n",
    "\n",
    "iou = intersection_over_union(predicted_bboxes, validation_bboxes)\n",
    "\n",
    "iou_threshold = 0.4\n",
    "\n",
    "print(\"Number of predictions where iou > threshold(%s): %s\" % (iou_threshold, (iou >= iou_threshold).sum()))\n",
    "print(\"Number of predictions where iou < threshold(%s): %s\" % (iou_threshold, (iou < iou_threshold).sum()))\n",
    "\n",
    "\n",
    "display_digits_with_boxes(validation_digits, predicted_labels, validation_labels, predicted_bboxes, validation_bboxes, iou, \"True and Predicted values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69700ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_digits_with_boxes(validation_digits, predicted_labels, validation_labels, predicted_bboxes, validation_bboxes, iou, \"True and Predicted values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e85b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (architecture, weights, and optimizer state)\n",
    "model.save('traffic_sign_model_final.keras')\n",
    "\n",
    "# Also save just the weights as a backup\n",
    "model.save_weights('traffic_sign_weights_final.weights.h5')\n",
    "\n",
    "print(\"Model saved successfully as 'traffic_sign_model_final.keras'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
